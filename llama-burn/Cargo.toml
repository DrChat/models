[package]
authors = ["guillaumelagrange <lagrange.guillaume.1@gmail.com>"]
license = "MIT OR Apache-2.0"
name = "llama-burn"
version = "0.1.0"
edition = "2021"
description = "Llama 3 large language model with Burn"

[features]
default = ["std"] # TODO: remove std default
std = []
pretrained = ["burn/network", "std", "dep:dirs"]

llama3 = ["dep:tiktoken-rs", "dep:rustc-hash", "dep:base64"]
tiny = ["dep:rust_tokenizers"]

[dependencies]
# Note: default-features = false is needed to disable std
burn = { path = "../../burn/crates/burn", default-features = false }
burn-import = { path = "../../burn/crates/burn-import" }
# burn = { version = "0.13.0", default-features = false }
# burn-import = { version = "0.13.0" }
itertools = { version = "0.12.1", default-features = false, features = [
    "use_alloc",
] }
dirs = { version = "5.0.1", optional = true }
serde = { version = "1.0.192", default-features = false, features = [
    "derive",
    "alloc",
] } # alloc is for no_std, derive is needed

# Tiktoken tokenizer (llama 3)
tiktoken-rs = { version = "0.5.8", optional = true }
base64 = { version = "0.22.1", optional = true }
rustc-hash = {version = "1.1.0", optional = true }

# SentencePiece tokenizer (tiny llama / llama 2)
rust_tokenizers = { version = "8.1.1", optional = true }

# Temporary; will be removed once we have the multinomial distribution
rand = { version = "0.8.5", default-features = false, features = [
    "std_rng",
] } # std_rng is for no_std

[dev-dependencies]
burn = { path = "../../burn/crates/burn", features = ["tch"] }
clap = { version = "4.5.4", features = ["derive"] }
# burn = { version = "0.13.0", features = ["wgpu"] }